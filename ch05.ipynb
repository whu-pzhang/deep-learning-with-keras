{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 神经网络用于计算机视觉\n",
    "\n",
    "本章包括以下内容：\n",
    "\n",
    "- 理解卷积神经网络（ConvNet）\n",
    "- 使用数据增强（data argument）来降低过拟合\n",
    "- 使用预训练的CNN进行特征提取\n",
    "- 微调预训练的CNN\n",
    "- 将CNN学到的内容及其如何做出分类决策可视化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from keras import models, layers, optimizers, losses, metrics\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(\n",
    "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 11, 11, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 3, 3, 64)          36928     \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 576)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                36928     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 93,322\n",
      "Trainable params: 93,322\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 在MNIST上训练CNN\n",
    "from keras.datasets import mnist\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "\n",
    "train_images = train_images.reshape((60000, 28, 28, 1)).astype('float32') / 255\n",
    "test_images = test_images.reshape((10000, 28, 28, 1)).astype('float32') / 255\n",
    "\n",
    "train_labels = to_categorical(train_labels)\n",
    "test_labels = to_categorical(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=optimizers.RMSprop(),\n",
    "    loss=losses.categorical_crossentropy,\n",
    "    metrics=[metrics.categorical_accuracy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 6s 98us/step - loss: 0.1730 - categorical_accuracy: 0.9467\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 6s 93us/step - loss: 0.0476 - categorical_accuracy: 0.9855\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 5s 90us/step - loss: 0.0327 - categorical_accuracy: 0.9900\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 6s 92us/step - loss: 0.0252 - categorical_accuracy: 0.9923\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 6s 92us/step - loss: 0.0208 - categorical_accuracy: 0.9937\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x14ff9139a710>"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_images, train_labels, epochs=5, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 1s 64us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.031015461185939057, 0.9908]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_images, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('mnist_cnn1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([7, 2, 1, 0, 4, 1])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = model.predict(test_images[:6], batch_size=1, verbose=1)\n",
    "np.argmax(results, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x216 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "f, ax = plt.subplots(1, 6, figsize=(15,3))\n",
    "for i, img in enumerate(test_images[:6]):\n",
    "    ax[i].imshow(img.reshape(28, 28), cmap=plt.cm.binary)\n",
    "    ax[i].axis('off')\n",
    "plt.show()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
